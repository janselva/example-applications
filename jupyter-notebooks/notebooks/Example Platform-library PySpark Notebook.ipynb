{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"clearfix\" style=\"padding: 10px; padding-left: 0px\">\n",
    "<img src=\"https://raw.githubusercontent.com/jupyter/nature-demo/master/images/jupyter-logo.png\" width=\"150px\" style=\"display: inline-block; margin-top: 5px;\">\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png\" width=\"150px\" class=\"pull-right\" style=\"display: inline-block; margin: 0px;\">\n",
    "</div>\n",
    "\n",
    "# Welcome to Example Platform-library PySpark Notebook\n",
    "\n",
    "It's a shared Jupyter server for you to learn and try out Jupyter notebook and perform interactive data analytics using PNDA platform libraries.\n",
    "\n",
    "In this example notebook, **JsonDataHandler**, a data handler implementation based on the assumption that the 'rawdata' field wrapped in Pnda avro record is a well-formatted in JSON.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "To run the codes below:\n",
    "\n",
    "1. Click on the cell to select it.\n",
    "2. Press `SHIFT+ENTER` on your keyboard or press the play button (<button class='fa fa-play icon-play btn btn-xs btn-default'></button>) in the toolbar above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sample datasets ###\n",
    "\n",
    "If you don't have existed datasets, there are two ways to generate sample datasets:\n",
    " * use data generation tool\n",
    " * use embedded cell in this notebook\n",
    "\n",
    "Data generation tool is pre-installed on this node at `/home/cloud-user/data_generator.py`. \n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p>** Usage **</p>\n",
    "```\n",
    "./data_generator.py --hosts '<host1_ip>,<host2_ip>'\\\n",
    "                    --metrics '<metric1>,<metric2>'\\\n",
    "                    --year <year>\\\n",
    "                    --month <month>\\\n",
    "                    --day <day of the day>\\\n",
    "                    --hour <hour of the day>\n",
    "```\n",
    "<p>\n",
    "[NOTE: if year|month|day|hour option is ignored, the script will extract values from current system time.]\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Alternative, you can simply run the cell below to generate sample network usage datesets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 1: ** Generate sample network usage datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import avro.schema\n",
    "import avro.io\n",
    "import io\n",
    "import datetime\n",
    "import uuid\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from random import randint\n",
    "from avro.datafile import DataFileWriter\n",
    "from avro.io import DatumWriter\n",
    "from argparse import RawTextHelpFormatter\n",
    "\n",
    "def generate_sample_datasets (host_ips, metric_ids, year, month, day, hour):\n",
    "    avro_schema = '''\n",
    "            {\"namespace\": \"pnda.entity\",\n",
    "             \"type\": \"record\",\n",
    "             \"name\": \"event\",\n",
    "             \"fields\": [\n",
    "                {\"name\": \"timestamp\", \"type\": \"long\"},\n",
    "                {\"name\": \"source\",    \"type\": \"string\"},\n",
    "                {\"name\": \"rawdata\",   \"type\": \"bytes\"}\n",
    "            ]}'''\n",
    "    schema = avro.schema.parse(avro_schema)\n",
    "    bytes_writer = io.BytesIO()\n",
    "    encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "    #create hdfs folder structure\n",
    "    dir = create_hdfs_dirs (year, month, day, hour)\n",
    "    filename = str(uuid.uuid4()) + '.avro'\n",
    "    filepath = dir + filename\n",
    "    tmp_file = '/tmp/' + filename\n",
    "    writer = DataFileWriter(open(tmp_file, \"w\"), DatumWriter(), schema)\n",
    "    start_dt = datetime.datetime(year, month, day, hour, 0, 0) \n",
    "    start_ts = int(time.mktime(start_dt.timetuple()))\n",
    "    end_dt = start_dt.replace(hour=hour+1)\n",
    "    end_ts = int(time.mktime(end_dt.timetuple()))\n",
    "\n",
    "    for ts in xrange(start_ts, end_ts, 1):\n",
    "        #generate random pnda record on per host ip basis\n",
    "        for host_ip in host_ips:\n",
    "           record = {}\n",
    "           record['timestamp'] = (ts * 1000)\n",
    "           record['source'] = 'samples'\n",
    "           #record['host_ip'] = host_ip\n",
    "           record['rawdata'] = generate_random_metrics(host_ip, metric_ids)\n",
    "           #encode avro\n",
    "           writer.append(record)\n",
    "    writer.close()\n",
    "    subprocess.Popen(['hadoop', 'fs', '-copyFromLocal', tmp_file, dir])\n",
    "    return filepath\n",
    "\n",
    "def generate_random_metrics (host_ip, metric_ids):\n",
    "    raw_data = {'host': host_ip}\n",
    "    for id in metric_ids:\n",
    "        raw_data[id] = str(randint(0, 100))\n",
    "    return json.dumps(raw_data).encode('utf-8')\n",
    "\n",
    "def create_hdfs_dirs (year, month, day, hour):\n",
    "    dir = \"/user/pnda/PNDA_datasets/datasets/source=samples/year=%0d/month=%02d/day=%02d/hour=%02d/\" % (year, month, day, hour)\n",
    "    subprocess.Popen(['hadoop', 'fs', '-mkdir', '-p', dir])\n",
    "    return dir    \n",
    "\n",
    "#example host ips (update as you wish)\n",
    "host_ips = ['10.0.0.1', '10.0.0.2', '10.0.0.3']\n",
    "#example metric list (update as you wish)\n",
    "metrics=['in_bytes', 'out_bytes', 'in_pks', 'out_pks']\n",
    "#generate example datasets (update year, month, day, and hour as you wish)\n",
    "generate_sample_datasets(host_ips, metrics, 2016, 4, 26, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with RDD ###\n",
    "RDD can be created automatically using PNDA platform libary. This allows data exploration using low-level RDD APIs.\n",
    "\n",
    "** Example 2: ** Create an instance of JsonDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from platformlibs.json_data_handler import JsonDataHandler\n",
    "handler = JsonDataHandler(sc, \"samples\", \"year=2016/month=04/day=26/hour=16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 3: ** Simple RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "rdd = handler.rdd\n",
    "# print total nubmer of records\n",
    "print rdd.count()\n",
    "\n",
    "# print one record\n",
    "pprint.pprint(rdd.take(1))\n",
    "\n",
    "# use MapR function to print list of unique router ips\n",
    "host_ips = rdd.map(lambda x: x['rawdata']['host']).distinct().collect()\n",
    "pprint.pprint(host_ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize high-level statistics ###\n",
    "PNDA platform library provide functions to return high-level statistics on per metric basis using `list_metric_ids()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 1: ** How many unique metrics of all routers have been collected? What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Speculate your anwser here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 4: ** Plot a bar chart to show the total number of records per host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot simple bar chart\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# use raw rdd \n",
    "host_stats = rdd.map(lambda x: (x['rawdata']['host'])) \\\n",
    "                .map(lambda x : (x, 1)) \\\n",
    "                .reduceByKey(lambda x, y: x + y) \\\n",
    "                .collect()\n",
    "host_ips = [x[0] for x in host_stats]\n",
    "counts = [x[1] for x in host_stats]\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "x = np.arange(len(host_ips))\n",
    "rects = ax.bar(x, counts, color='y')\n",
    "plt.xticks(x, host_ips, rotation=45) \n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach 'counts' labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "autolabel(rects) # add label on bar\n",
    "plt.ylabel('counts')\n",
    "plt.title('Statistics of hosts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 2: ** Generate a bar chart to show total number of records per metric of host 10.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Speculate your anwser here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing interactive UI ###\n",
    "Interactivity introduction to your notebook can be done by adding widgets provided in the `ipywidgets` package. Each widget consists of two parts: the UI element (e.g. Text Input, sliding bar, etc.) and an event handler. \n",
    "\n",
    "** Example 5: ** Interactive visualization of total number of records per metric of a particular host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "options= ['--select--'] + sorted(host_ips)\n",
    "selected_host = \"--select--\"\n",
    "\n",
    "host_ip_widget = widgets.Dropdown(description='Host IP:', width=100, options=options)\n",
    "display(host_ip_widget)\n",
    "# diplaying the limits input widget:\n",
    "limits_input = widgets.Text(description=\"limits :\", width=200)\n",
    "display(limits_input)\n",
    "# preparing a container to put in the created checkbox per host ip\n",
    "checkboxes = []\n",
    "cb_container=widgets.HBox()\n",
    "display(cb_container)\n",
    "\n",
    "# add button that updates the graph based on the checkboxes\n",
    "button = widgets.Button(description=\"submit\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    selected_host = host_ip_widget.value\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        # attach 'counts' labels\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%d' % int(height),\n",
    "                    ha='center', va='bottom')\n",
    "    limit = -1\n",
    "    if limits_input.value:\n",
    "        limit = int(limits_input.value)\n",
    "        \n",
    "    filters={}\n",
    "    metrics = None\n",
    "    if selected_host != \"--select--\":\n",
    "        filters['host']=[selected_host] \n",
    "        m_stats = handler.list_metric_ids(limit=limit, filters=filters)\n",
    "        if len(m_stats) > 0:\n",
    "            \n",
    "            m_lst = [x[0] for x in m_stats]\n",
    "            counts = [x[1] for x in m_stats]\n",
    "            x = np.arange(len(m_lst))\n",
    "            fig, ax = plt.subplots(figsize=(15, 8))\n",
    "            metric_rects = ax.bar(x, counts, color='y')\n",
    "            plt.xticks(x, m_lst, rotation='vertical') \n",
    "            plt.ylabel ('counts')\n",
    "            patch = mpatches.Patch(color='y', label=selected_host)\n",
    "            plt.legend(handles=[patch])\n",
    "            autolabel(metric_rects)\n",
    "            plt.draw()\n",
    "    else:\n",
    "        print \"Please select a host ip from dropdown list.\"\n",
    "        \n",
    "button.on_click(on_button_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 6: ** Interactive time series visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ipywidgets import *\n",
    "from operator import add\n",
    "from IPython.display import display\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "dateFormatString = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "colors=['b', 'c', 'y', 'm', 'r']\n",
    "\n",
    "# displaying the metric id input widget\n",
    "metric_id_input = widgets.Text(description=\"metric id:\", width=200)\n",
    "display(metric_id_input)\n",
    "\n",
    "host_ip_input = widgets.Text(description=\"host ip:\", width=200, value='edit and hit to add')\n",
    "display(host_ip_input)\n",
    "\n",
    "#preparing the plot \n",
    "plots = dict()  \n",
    "\n",
    "#preparing a container to put in created checkbox per host ip\n",
    "checkboxes = []  \n",
    "cb_container = widgets.HBox()  \n",
    "display(cb_container)\n",
    "\n",
    "#preparing update button\n",
    "update_button = widgets.Button(description=\"Update\")\n",
    "\n",
    "#normalise data with 5-min interval\n",
    "def post_process(data):\n",
    "    def f(x): \n",
    "        sum_val = 0\n",
    "        for val in x:\n",
    "            sum_val = sum_val + x[0][1]\n",
    "        return sum_val\n",
    "    data_rdd = sc.parallelize(data).map(lambda x: (x[0], int(x[1]))).foldByKey(0, add).sortBy(lambda x: x[0]).groupBy(lambda x : (calendar.timegm(time.strptime(datetime.datetime.fromtimestamp(x[0]/1000).strftime('%Y-%m-%d %H:%M:%S'), dateFormatString))/(5*60))).map(lambda x : (x[0],list(x[1]))).mapValues(f).map(lambda x: (datetime.datetime.fromtimestamp(x[0] * 6*50), x[1]))\n",
    "    return data_rdd.keys().collect(), data_rdd.values().collect()\n",
    "\n",
    "#function to deal with the added host ip\n",
    "def handle_submit(sender):  \n",
    "    exists = False\n",
    "    for cb in checkboxes:\n",
    "        if cb.description is host_ip_input.value:\n",
    "            exists = True\n",
    "    if not exists and len(checkboxes)<5:\n",
    "        #add a new checkbox for the new host ip\n",
    "        checkboxes.append(widgets.Checkbox(description = host_ip_input.value, value=True, width=90))\n",
    "        cb_container.children=[i for i in checkboxes]\n",
    "        if len(checkboxes) == 1:\n",
    "            display(update_button)\n",
    "\n",
    "#function to deal with the checkbox update button       \n",
    "def on_button_clicked(b): \n",
    "    \n",
    "    metric = metric_id_input.value\n",
    "    host_ips = []\n",
    "    results = []\n",
    "    for c in cb_container.children:\n",
    "        if c.value:\n",
    "            host_ips.append(c.description)            \n",
    "    \n",
    "    for host in host_ips:\n",
    "        filters = {'metrics': metric, 'host': host}\n",
    "        #print handler.execute_query(filters=filters)\n",
    "        results.append((host, handler.execute_query(filters=filters)[0][1]))\n",
    "        \n",
    "    i=0\n",
    "    if len(results) > 0:\n",
    "        # Plot things...\n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        ax=fig.add_subplot(111)\n",
    "        for result in results:\n",
    "            label = result[0]\n",
    "            timestamps, values = post_process(result[1])\n",
    "            ax.plot_date(timestamps, values, c=colors[i], label=label)\n",
    "            i=i+1\n",
    "        ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%H:%M:%S\"))\n",
    "        plt.ylabel(metric_id_input.value)\n",
    "        plt.xlabel(\"time of the day\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.gray()    \n",
    "        plt.show()\n",
    "        \n",
    "update_button.on_click(on_button_clicked)  \n",
    "host_ip_input.on_submit(handle_submit)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 3: ** generate scatter plots to show packet/bytes drops (e.g. use in_byte metric) of a partiular host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Speculate your anwser here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark/Python2 (Anaconda)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "1557e450223e4dde8c2413a5ee83e705": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "1afdbacd1b0b478aa01978edac6c190a": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "1ba2b95d0e4d4a26a7aa819dc8534c6a": {
     "views": []
    },
    "2db1cd0c66dd4e8196a900db826d64c8": {
     "views": []
    },
    "38670bab911f412191a9b3deb84babc7": {
     "views": []
    },
    "461bb60055dd4397b778a407640d1d99": {
     "views": []
    },
    "533f372af51e4cb79e2122e986d701df": {
     "views": []
    },
    "561a2c0073014a1d8cad39649bc96573": {
     "views": []
    },
    "58ce38b80de34d6e82a4d160febff999": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "633ca203e85541b59f9131e83f6b12bb": {
     "views": []
    },
    "634e89cc27f14c5eb125d8294ab0e262": {
     "views": []
    },
    "63bf2949f1ab4cdbb73d1d0d6d20dbd0": {
     "views": []
    },
    "657e67c80c174b04bbd1f8cee14674ef": {
     "views": []
    },
    "6b7ff28cf96145abbcb000a6d784b58c": {
     "views": []
    },
    "7cf1b6bb25d841b0b83bf337300df6fd": {
     "views": []
    },
    "810c709e9cc84968a1c20d1d13db8acf": {
     "views": []
    },
    "a2439b82434d41a3b63efdbf3eee6519": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "a4848088511d42379c3daf05b7150343": {
     "views": []
    },
    "ac64a66ddb0e4cf9bd3cd37cf4275b28": {
     "views": []
    },
    "ade75b3524bc42d39979108791ac27e0": {
     "views": []
    },
    "aeac437c13634b02be44b86ce14a16d7": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "b2d5229dfa0c4bc093922e6fd9afbd7a": {
     "views": []
    },
    "b81aa794d7d74402bb68519be24bb444": {
     "views": []
    },
    "bd62dae252ac444fbc377bec6458eb6b": {
     "views": []
    },
    "c6d9fa2d6f2a4f0fb0b662d6bd89c6a4": {
     "views": []
    },
    "cc93c8dda54d4f139f41b42c3dba67ad": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "ce3a67a85dcf4cefbe5fa3e9e27644d8": {
     "views": []
    },
    "df0a9835ec7c49ffaa7992c919a6ddcf": {
     "views": []
    },
    "e61981d0808e4ce1ac91ad16d8f3b55f": {
     "views": []
    },
    "e87b1311dbde4cd0bc020eb484d72f5b": {
     "views": []
    },
    "e9353bafbf6a4a9b8b9de0747078720f": {
     "views": []
    },
    "f0874b40c3da49fbb514e3f9f2047df3": {
     "views": []
    },
    "f2bb960e4fc2454fa1be3b679c7fd078": {
     "views": []
    },
    "fe575e9009c54084bd0a27bdd4c03382": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
